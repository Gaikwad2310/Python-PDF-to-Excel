# Assuming the first column is key and should never be blank
merged_rows = []
prev_row = None

for _, row in df.iterrows():
    if pd.isna(row.iloc[0]) or str(row.iloc[0]).strip() == '':
        if prev_row is not None:
            prev_row = [
                (prev if pd.isna(val) or str(val).strip() == '' else str(prev) + ' ' + str(val))
                for prev, val in zip(prev_row, row)
            ]
    else:
        if prev_row is not None:
            merged_rows.append(prev_row)
        prev_row = list(row)

if prev_row is not None:
    merged_rows.append(prev_row)

# Convert to DataFrame
cleaned_df = pd.DataFrame(merged_rows, columns=df.columns)

print(cleaned_df)

import re
import pdfplumber
import camelot

def find_toc_page(pdf_path, max_pages=5):
    with pdfplumber.open(pdf_path) as pdf:
        for i in range(min(max_pages, len(pdf.pages))):
            text = pdf.pages[i].extract_text()
            if text and ("contents" in text.lower() or "chapter" in text.lower()):
                return i + 1  # return 1-based page index
    return None

def extract_page_number_from_toc(pdf_path, subchapter_title, max_pages=5):
    toc_page = find_toc_page(pdf_path, max_pages)
    if toc_page is None:
        print("Table of Contents not found.")
        return None

    with pdfplumber.open(pdf_path) as pdf:
        text = pdf.pages[toc_page - 1].extract_text()
        lines = text.split('\n')

        for line in lines:
            if subchapter_title.lower() in line.lower():
                match = re.search(r'(\d+)\s*$', line.strip())  # extract ending number
                if match:
                    return int(match.group(1))
    print(f"Subchapter '{subchapter_title}' not found in ToC.")
    return None

def extract_tables_from_subchapter(pdf_path, subchapter_title, offset_pages=2):
    page_num = extract_page_number_from_toc(pdf_path, subchapter_title)
    if not page_num:
        return []

    pages = list(range(page_num, page_num + offset_pages + 1))  # include following pages
    page_str = ",".join(map(str, pages))
    tables = camelot.read_pdf(pdf_path, pages=page_str, strip_text='\n')
    return [table.df for table in tables]

# Example usage
pdf_path = "your_file.pdf"
subchapter = "2.1 Revenue Analysis"

tables = extract_tables_from_subchapter(pdf_path, subchapter)

if tables:
    print(f"Extracted {len(tables)} tables.")
    print(tables[0])  # Show first table
else:
    print("No tables found.")

import camelot
import pandas as pd

# Extract tables
tables = camelot.read_pdf("file.pdf", pages="1", flavor="stream")

# Get the first table
df = tables[0].df

# Clean newlines
df = df.applymap(lambda x: x.replace('\n', ' ').strip() if isinstance(x, str) else x)

# Optionally set first row as header
df.columns = df.iloc[0]
df = df[1:].reset_index(drop=True)

# Handle merged rows (assumes first column should not be empty)
merged_rows = []
prev_row = None

for _, row in df.iterrows():
    if row.iloc[0].strip() == '':  # Assume first column (e.g., ID) is the key
        # Merge into previous row
        if prev_row is not None:
            prev_row = [
                (prev if val.strip() == '' else prev + ' ' + val)
                for prev, val in zip(prev_row, row)
            ]
    else:
        if prev_row is not None:
            merged_rows.append(prev_row)
        prev_row = list(row)

# Append the last processed row
if prev_row is not None:
    merged_rows.append(prev_row)

# Convert to DataFrame
cleaned_df = pd.DataFrame(merged_rows, columns=df.columns)

print(cleaned_df)

import os
import shutil

def create_folders_and_copy_pdf(base_path, folder_dict, pdf_path):
    if not os.path.isfile(pdf_path):
        print(f"[ERROR] PDF file does not exist at: {pdf_path}")
        return

    pdf_filename = os.path.basename(pdf_path)
    print(f"[INFO] Starting folder creation and PDF copying...")
    print(f"[INFO] PDF to copy: {pdf_filename}\n")

    for level1 in folder_dict:
        path1 = os.path.join(base_path, level1)
        os.makedirs(path1, exist_ok=True)
        print(f"[CREATE] Level 1 folder: {path1}")

        for level2 in folder_dict[level1]:
            path2 = os.path.join(path1, level2)
            os.makedirs(path2, exist_ok=True)
            print(f"[CREATE] â””â”€â”€ Level 2 folder: {path2}")

            for level3 in folder_dict[level1][level2]:
                path3 = os.path.join(path2, level3)
                os.makedirs(path3, exist_ok=True)
                print(f"[CREATE]     â””â”€â”€ Level 3 folder: {path3}")

                # Copy PDF to this folder
                dest_pdf_path = os.path.join(path3, pdf_filename)
                shutil.copy2(pdf_path, dest_pdf_path)
                print(f"[COPY]         â””â”€â”€ PDF copied to: {dest_pdf_path}")

    print("\nâœ… All folders created and PDF copied successfully.\n")

# === Example usage ===
folder_structure = {
    'A': {
        'A1': ['A1a', 'A1b'],
        'A2': ['A2a']
    },
    'B': {
        'B1': ['B1a']
    }
}

base_output_path = "/path/to/create/folders"    # ðŸ” Replace this with your target base directory
pdf_source_path = "/path/to/your/file.pdf"      # ðŸ” Replace this with the actual PDF file

create_folders_and_copy_pdf(base_output_path, folder_structure, pdf_source_path)

import os

def extract_folder_structure(master_path):
    folder_structure = {}

    for level1 in os.listdir(master_path):
        path1 = os.path.join(master_path, level1)
        if os.path.isdir(path1):
            folder_structure[level1] = {}
            
            for level2 in os.listdir(path1):
                path2 = os.path.join(path1, level2)
                if os.path.isdir(path2):
                    folder_structure[level1][level2] = []
                    
                    for level3 in os.listdir(path2):
                        path3 = os.path.join(path2, level3)
                        if os.path.isdir(path3):
                            folder_structure[level1][level2].append(level3)

    return folder_structure

# Example usage
master_folder_path = "/path/to/master/folder"
structure = extract_folder_structure(master_folder_path)

# Print the structure clearly
import pprint
pprint.pprint(structure)

import os
import shutil

def create_folders_and_copy_pdf(base_path, folder_dict, pdf_path):
    for level1 in folder_dict:
        path1 = os.path.join(base_path, level1)
        os.makedirs(path1, exist_ok=True)

        for level2 in folder_dict[level1]:
            path2 = os.path.join(path1, level2)
            os.makedirs(path2, exist_ok=True)

            for level3 in folder_dict[level1][level2]:
                path3 = os.path.join(path2, level3)
                os.makedirs(path3, exist_ok=True)

                # Copy PDF into level3 folder
                pdf_filename = os.path.basename(pdf_path)
                dest_pdf_path = os.path.join(path3, pdf_filename)
                shutil.copy2(pdf_path, dest_pdf_path)

    print("Folder structure created and PDF copied.")

# === Example usage ===
# Folder dictionary (you can reuse output from the previous function)
folder_structure = {
    'A': {
        'A1': ['A1a', 'A1b'],
        'A2': ['A2a']
    },
    'B': {
        'B1': ['B1a']
    }
}

base_output_path = "/path/to/create/folders"    # Replace this with the base output path
pdf_source_path = "/path/to/your/file.pdf"      # Replace this with the actual PDF path

create_folders_and_copy_pdf(base_output_path, folder_structure, pdf_source_path)

import numpy as np
import pandas as pd
from scipy.interpolate import interp2d
import matplotlib.pyplot as plt

# Local vol surface as a 2D array over strikes (K) and maturities (T)
def local_vol_surface(strikes, maturities, local_vol_values):
    return interp2d(strikes, maturities, local_vol_values, kind='linear')

# Dupire PDE: finite difference for call option pricing
def price_option_dupire(S0, K, T, r, local_vol_func, S_grid_size=200, T_steps=100):
    S_max = 2 * S0
    dS = S_max / S_grid_size
    dt = T / T_steps

    S = np.linspace(0.001, S_max, S_grid_size)
    V = np.maximum(S - K, 0)  # Final payoff

    for j in range(T_steps):
        t = T - j * dt
        sigma = local_vol_func(K, t)

        # Finite difference coefficients
        A = np.zeros(S_grid_size)
        B = np.zeros(S_grid_size)
        C = np.zeros(S_grid_size)

        for i in range(1, S_grid_size - 1):
            delta = (V[i+1] - V[i-1]) / (2 * dS)
            gamma = (V[i+1] - 2*V[i] + V[i-1]) / (dS**2)

            vol_sq = sigma**2
            A[i] = 0.5 * vol_sq * S[i]**2 * gamma
            B[i] = r * S[i] * delta
            C[i] = -r * V[i]

        V[1:-1] += dt * (A[1:-1] + B[1:-1] + C[1:-1])
        V[0] = 0
        V[-1] = S_max - K * np.exp(-r * (T - t))

    return np.interp(S0, S, V)

# Evaluation function
def evaluate_local_volatility(S0, r, strikes, maturities, local_vol_values, market_prices):
    lv_func = local_vol_surface(strikes, maturities, local_vol_values)

    results = []
    for K, T, C_market in zip(strikes, maturities, market_prices):
        C_model = price_option_dupire(S0, K, T, r, lv_func)
        error = abs(C_market - C_model)
        results.append((K, T, C_market, C_model, error))

    df_results = pd.DataFrame(results, columns=["Strike", "Maturity", "Market_Price", "Model_Price", "Abs_Error"])
    return df_results

import math
from scipy.stats import norm
from scipy.optimize import brentq

class BlackScholesModel:
    def __init__(self, S, K, T, r):
        """
        S: Spot price
        K: Strike price
        T: Time to maturity (in years)
        r: Risk-free interest rate
        """
        self.S = S
        self.K = K
        self.T = T
        self.r = r

    def call_price(self, sigma):
        """Black-Scholes formula for a European call option."""
        d1 = (math.log(self.S / self.K) + (self.r + 0.5 * sigma ** 2) * self.T) / (sigma * math.sqrt(self.T))
        d2 = d1 - sigma * math.sqrt(self.T)
        return self.S * norm.cdf(d1) - self.K * math.exp(-self.r * self.T) * norm.cdf(d2)

    def put_price(self, sigma):
        """Black-Scholes formula for a European put option."""
        d1 = (math.log(self.S / self.K) + (self.r + 0.5 * sigma ** 2) * self.T) / (sigma * math.sqrt(self.T))
        d2 = d1 - sigma * math.sqrt(self.T)
        return self.K * math.exp(-self.r * self.T) * norm.cdf(-d2) - self.S * norm.cdf(-d1)

class ImpliedVolatilityCalculator:
    def __init__(self, bs_model, option_type='call'):
        """
        bs_model: Instance of BlackScholesModel
        option_type: 'call' or 'put'
        """
        self.bs_model = bs_model
        self.option_type = option_type

    def implied_volatility(self, market_price, sigma_lower=1e-6, sigma_upper=5.0, tol=1e-6):
        """
        Calculate implied volatility using Brent's method.
        market_price: Observed market price of the option
        """
        if self.option_type == 'call':
            price_fn = self.bs_model.call_price
        elif self.option_type == 'put':
            price_fn = self.bs_model.put_price
        else:
            raise ValueError("option_type must be 'call' or 'put'")

        def objective(sigma):
            return price_fn(sigma) - market_price

        try:
            return brentq(objective, sigma_lower, sigma_upper, xtol=tol)
        except ValueError:
            return float('nan')  # No solution found

# Example usage
if __name__ == "__main__":
    S = 100       # Spot price
    K = 100       # Strike price
    T = 1.0       # Time to maturity
    r = 0.05      # Risk-free interest rate
    C_market = 10 # Market price of call option

    bs = BlackScholesModel(S, K, T, r)
    iv_calc = ImpliedVolatilityCalculator(bs, option_type='call')
    iv = iv_calc.implied_volatility(C_market)
    print(f"Implied Volatility (Call): {iv:.6f}")

You are an expert in professional technical document generation. Your task is to update a performance and monitoring report using:

1. A reference PDF document that contains the previous quarterâ€™s version of the report.
2. A table of current quarter KPI results (provided separately).
3. Detailed user instructions.

Replicate the structure, formatting, and section numbering exactly as in the original document. Do not invent data. Use unchanged content directly from the original PDF where indicated, and update only the specific parts mentioned. Your writing must be formal, consistent, and clearly organized.
You are generating an updated version of a model performance report using:
- A PDF report from a previous quarter (already uploaded)
- A current quarter KPI table (provided separately)

The document must follow the original section structure precisely and contain fully updated or copied content where needed.

---

**1. Introduction**

**1.1 Executive Summary**  
Write a concise but complete executive summary based on the updated content of the entire document. Include highlights from the KPI results, key trends, and overall model performance. The summary must preview all the key findings covered in Chapters 3 to 5.

**1.2 Model Stakeholders**  
Copy this section **exactly** as it appears in the uploaded PDF. No changes are required.

**1.3 Test Source**  
Copy this section from the uploaded PDF, but apply this specific change:  
[INSERT SMALL CHANGE HERE].  
Keep everything else intact, preserving original formatting and tone.

---

**2. Monitoring Plan**  
Copy the entire â€œMonitoring Planâ€ section exactly as in the uploaded PDF. Do not alter anything.

---

**3. Model Testing and Performance**  
ðŸ’¡ This chapter must be **fully written** with **tables and analysis**, not skipped or summarized.

**3.1 Key Performance Indicator Results**  
Use the provided current quarter KPI table. Reproduce this as a clearly formatted table.  
Then, write a paragraph analyzing each KPI:  
- Explain what each metric indicates  
- Mention any improvement or decline compared to previous quarter  
- Use a clear, structured format (e.g., bullets or subheadings)

**3.2 Overall Rating, Weighting Methodology, and Rationale**  
Recalculate the overall model rating based on the current KPIs.  
Use the same structure as in the PDF:  
- Include updated scores  
- Describe the weighting methodology  
- Provide rationale for the new overall score  
ðŸ’¡ This section must be fully written with all subsections covered â€” no placeholders or skips.

**3.3 KPI History**  
Create a 4-quarter KPI comparison table.  
- Use current KPI data (provided)  
- Extract the previous 3 quarters' values from the uploaded PDF  
Then, write a comparative analysis below the table:  
- Highlight trends  
- Explain consistent or diverging behaviors  
- Be specific and technical, not vague

---

**4. Attestations**  
ðŸ’¡ This chapter must be complete. Both subsections should be **copied and lightly updated**.

**4.1 Regression Testing**  
Copy from the PDF and update the date or version reference to match the current testing cycle. Do not skip this section.

**4.2 Monitoring Plan is Up-to-Date**  
Copy this section and update only the date. Do not shorten or summarize.

---

**5. Conclusion**  
Write a new conclusion summarizing:  
- Overall model health  
- Key changes in this quarterâ€™s results  
- Any issues or regressions  
- Final recommendation

ðŸ’¡ This section must reflect insights from the KPI analysis and rating sections. Be formal and analytical.

---

**References**  
Copy the â€œReferencesâ€ section **exactly** as it appears in the PDF. No changes are allowed.

---

**Final Instructions**  
- Output must include **all sections and subsections in full**  
- Use complete paragraphs, tables, and technical tone  
- Do not leave any section empty or placeholder text  
- Use headings, numbering, and formatting exactly as in the original document

import pandas as pd
import sympy as sp
import numpy as np

def _create_lv_calculators_k():
    """
    Helper to create numerical functions from symbolic expressions,
    where SVI is parameterized by strike k.
    """
    # Define symbols. k is strike, y is log-moneyness.
    k, y, a, b, rho, m, sigma = sp.symbols('k y a b rho m sigma')
    
    # SVI total variance expression is a function of strike k
    w_k_expr = a + b * (rho * (k - m) + sp.sqrt((k - m)**2 + sigma**2))

    # Calculate derivatives of w w.r.t. k
    dw_dk = sp.diff(w_k_expr, k)
    d2w_dk2 = sp.diff(dw_dk, k)

    # Use the chain rule to find derivatives w.r.t. y
    # âˆ‚w/âˆ‚y = (âˆ‚w/âˆ‚k) * (âˆ‚k/âˆ‚y) and âˆ‚k/âˆ‚y = k
    dw_dy = dw_dk * k
    # âˆ‚Â²w/âˆ‚yÂ² = kÂ² * (âˆ‚Â²w/âˆ‚kÂ²) + k * (âˆ‚w/âˆ‚k)
    d2w_dy2 = d2w_dk2 * k**2 + dw_dk * k
    
    # Denominator from the local volatility formula
    denominator_expr = (
        1 - y / w_k_expr * dw_dy +
        0.5 * d2w_dy2 +
        0.25 * (1/w_k_expr**2 - 1/w_k_expr - 0.25) * dw_dy**2
    )
    
    # Compile symbolic expressions into fast numerical functions
    w_func = sp.lambdify((k, a, b, rho, m, sigma), w_k_expr, 'numpy')
    den_func = sp.lambdify((k, y, a, b, rho, m, sigma), denominator_expr, 'numpy')
    
    return w_func, den_func

# Pre-compile the functions for efficiency
_w_calculator_k, _denominator_calculator_k = _create_lv_calculators_k()

def add_local_volatility_k(df: pd.DataFrame, S0: float, r: float) -> pd.DataFrame:
    """
    Calculates local volatility with SVI parameterized by strike k.

    The input DataFrame must contain columns: 'k' (strike), 'T' (maturity),
    and SVI parameters: 'a', 'b', 'rho', 'm', 'sigma'.
    """
    df_result = df.copy()
    
    # Extract data from DataFrame columns
    k = df_result['k']
    T = df_result['T']
    y = np.log(k / (S0 * np.exp(r * T)))
    params = [df_result[col] for col in ['a', 'b', 'rho', 'm', 'sigma']]

    # Numerator: âˆ‚w/âˆ‚T (using finite difference)
    # This captures time-dependence of w through the forward price in k(y,T)
    dT = 1e-4
    k_at_T_plus_dt = k * np.exp(r * dT) # k(y, T+dT) = k(y,T) * exp(r*dT)
    
    w_at_T = _w_calculator_k(k, *params)
    w_at_T_plus_dt = _w_calculator_k(k_at_T_plus_dt, *params)
    numerator = (w_at_T_plus_dt - w_at_T) / dT

    # Denominator calculation using the pre-compiled symbolic result
    denominator = _denominator_calculator_k(k, y, *params)
    
    # Calculate local variance, handling numerical issues
    local_variance = np.divide(numerator, denominator, 
                               out=np.full_like(numerator, np.nan), 
                               where=(denominator!=0))
    local_variance[local_variance < 0] = 0

    df_result['local_volatility'] = np.sqrt(local_variance)
    
    return df_result

# --- Example Usage ---
if __name__ == "__main__":
    # Create a sample DataFrame
    data = {
        'T': [0.5, 0.5, 0.5, 1.0, 1.0, 1.0],
        'k': [90, 100, 110, 90, 100, 110],
        'a': [0.035, 0.035, 0.035, 0.025, 0.025, 0.025],
        'b': [0.004, 0.004, 0.004, 0.005, 0.005, 0.005], # Scaled for k
        'rho': [-0.6, -0.6, -0.6, -0.5, -0.5, -0.5],
        'm': [100, 100, 100, 102, 102, 102], # m is now in strike units
        'sigma': [15, 15, 15, 18, 18, 18] # sigma is now in strike units
    }
    sample_df = pd.DataFrame(data)

    # Call the function with market data
    result_df_k = add_local_volatility_k(df=sample_df, S0=100.0, r=0.01)

    print(result_df_k)

import pandas as pd
import sympy as sp
import numpy as np

def create_local_vol_function():
    y, T, a, b, rho, m, sigma = sp.symbols('y T a b rho m sigma')
    w_expr = a + b * (rho * (y - m) + sp.sqrt((y - m)**2 + sigma**2))
    dw_dy = sp.diff(w_expr, y)
    d2w_dy2 = sp.diff(dw_dy, y)
    den_expr = (1 - y / w_expr * dw_dy + 1/2 * d2w_dy2 + 1/4 * (1/w_expr**2 - 1/w_expr - 1/4) * dw_dy**2)
    den_func = sp.lambdify((y, a, b, rho, m, sigma), den_expr, 'numpy')
    w_func = sp.lambdify((y, a, b, rho, m, sigma), w_expr, 'numpy')
    return w_func, den_func

def calculate_local_volatility(df):
    df['y'] = np.log(df['k'] / (df['S'] * np.exp(df['r'] * df['T'])))
    w_func, den_func = create_local_vol_function()
    y_vals, a_vals, b_vals, rho_vals, m_vals, sigma_vals, T_vals = df['y'], df['a'], df['b'], df['rho'], df['m'], df['sigma'], df['T']
    w_t = w_func(y_vals, a_vals, b_vals, rho_vals, m_vals, sigma_vals)
    denominator = den_func(y_vals, a_vals, b_vals, rho_vals, m_vals, sigma_vals)
    dT = 0.001
    w_t_plus_dt = w_func(y_vals, a_vals, b_vals, rho_vals, m_vals, sigma_vals)
    total_variance_t = w_t * T_vals
    total_variance_t_plus_dt = w_t_plus_dt * (T_vals + dT)
    numerator = (total_variance_t_plus_dt - total_variance_t) / dT
    local_variance = np.full_like(numerator, np.nan)
    valid_mask = (denominator != 0)
    local_variance[valid_mask] = numerator[valid_mask] / denominator[valid_mask]
    local_variance[local_variance < 0] = 0
    df['local_volatility'] = np.sqrt(local_variance)
    return df

# Example usage
if __name__ == "__main__":
    data = {
        'T': [0.5, 0.5, 0.5, 1.0, 1.0, 1.0],
        'k': [90, 100, 110, 90, 100, 110],
        'S': [100]*6,
        'r': [0.01]*6,
        'a': [0.035, 0.035, 0.035, 0.025, 0.025, 0.025],
        'b': [0.4, 0.4, 0.4, 0.5, 0.5, 0.5],
        'rho': [-0.6, -0.6, -0.6, -0.5, -0.5, -0.5],
        'm': [0.01, 0.01, 0.01, 0.02, 0.02, 0.02],
        'sigma': [0.15, 0.15, 0.15, 0.18, 0.18, 0.18]
    }
    df = pd.DataFrame(data)
    result_df = calculate_local_volatility(df)
    print(result_df)

import pandas as pd
import sympy as sp
import numpy as np

def _create_lv_calculators():
    """Helper to create numerical functions from symbolic expressions."""
    y, a, b, rho, m, sigma = sp.symbols('y a b rho m sigma')
    
    # SVI implied variance (sigma_imp^2), denoted as w in the formula
    w_expr = a + b * (rho * (y - m) + sp.sqrt((y - m)**2 + sigma**2))
    
    # Symbolic derivatives w.r.t. log-moneyness y
    dw_dy = sp.diff(w_expr, y)
    d2w_dy2 = sp.diff(dw_dy, y)

    # Denominator from the local volatility formula
    denominator_expr = (
        1 - y / w_expr * dw_dy + 
        0.5 * d2w_dy2 +
        0.25 * (1/w_expr**2 - 1/w_expr - 0.25) * dw_dy**2
    )
    
    # Compile symbolic expressions into fast numerical functions
    w_func = sp.lambdify((y, a, b, rho, m, sigma), w_expr, 'numpy')
    den_func = sp.lambdify((y, a, b, rho, m, sigma), denominator_expr, 'numpy')
    
    return w_func, den_func

# Pre-compile the functions once for efficiency
_w_calculator, _denominator_calculator = _create_lv_calculators()

def add_local_volatility(df: pd.DataFrame, S0: float, r: float) -> pd.DataFrame:
    """
    Calculates local volatility and adds it as a column to the DataFrame.

    The input DataFrame must contain columns: 'k' (strike), 'T' (maturity),
    and SVI parameters: 'a', 'b', 'rho', 'm', 'sigma'.
    """
    df_result = df.copy()
    
    # Extract data and calculate log-moneyness y
    y = np.log(df_result['k'] / (S0 * np.exp(r * df_result['T'])))
    params = [df_result[col] for col in ['a', 'b', 'rho', 'm', 'sigma']]
    T = df_result['T']

    # Numerator: Derivative of total variance (w*T) w.r.t T (using finite difference)
    dT = 1e-4
    total_variance_t = _w_calculator(y, *params) * T
    total_variance_t_plus_dt = _w_calculator(y, *params) * (T + dT)
    numerator = (total_variance_t_plus_dt - total_variance_t) / dT

    # Denominator calculation using the pre-compiled symbolic result
    denominator = _denominator_calculator(y, *params)
    
    # Calculate local variance, handling numerical issues
    local_variance = np.divide(numerator, denominator, 
                               out=np.full_like(numerator, np.nan), 
                               where=(denominator!=0))
    local_variance[local_variance < 0] = 0

    df_result['local_volatility'] = np.sqrt(local_variance)
    
    return df_result

# --- Example Usage ---
if __name__ == "__main__":
    # Create a sample DataFrame
    data = {
        'T': [0.5, 0.5, 0.5, 1.0, 1.0, 1.0],
        'k': [90, 100, 110, 90, 100, 110],
        'a': [0.035, 0.035, 0.035, 0.025, 0.025, 0.025],
        'b': [0.4, 0.4, 0.4, 0.5, 0.5, 0.5],
        'rho': [-0.6, -0.6, -0.6, -0.5, -0.5, -0.5],
        'm': [0.01, 0.01, 0.01, 0.02, 0.02, 0.02],
        'sigma': [0.15, 0.15, 0.15, 0.18, 0.18, 0.18]
    }
    sample_df = pd.DataFrame(data)

    # Call the function with market data
    result_df = add_local_volatility(df=sample_df, S0=100.0, r=0.01)

    print(result_df)
